{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ungraded Lab: Practice with the Keras Functional API\n",
    "\n",
    "This lab will demonstrate how to build models with the Functional syntax. You'll build one using the Sequential API and see how you can do the same with the Functional API. Both will arrive at the same architecture and you can train and evaluate it as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "graphviz is already the newest version (2.42.2-3build2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (0.24.2)\n",
      "Requirement already satisfied: pydot in /usr/local/lib/python3.8/dist-packages (1.4.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.8/dist-packages (from pydot) (3.0.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ! apt update\n",
    "# ! apt install git-all\n",
    "\n",
    "! apt install graphviz -yq\n",
    "! pip install pandas scikit-learn pydot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "import pydot\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential API\n",
    "\n",
    "Here is how we use the `Sequential()` class to build a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04Y-C9RYUTes"
   },
   "outputs": [],
   "source": [
    "def build_model_with_sequential():\n",
    "    \n",
    "    # instantiate a Sequential class and linearly stack the layers of your model\n",
    "    seq_model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                                            tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                            tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API\n",
    "\n",
    "And here is how you build the same model above with the functional syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_functional():\n",
    "    \n",
    "    # instantiate the input Tensor\n",
    "    input_layer = tf.keras.Input(shape=(28, 28))\n",
    "    \n",
    "    # stack the layers using the syntax: new_layer()(previous_layer)\n",
    "    flatten_layer = tf.keras.layers.Flatten()(input_layer)\n",
    "    first_dense = tf.keras.layers.Dense(128, activation=tf.nn.relu)(flatten_layer)\n",
    "    output_layer = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(first_dense)\n",
    "    \n",
    "    # declare inputs and outputs\n",
    "    func_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return func_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model and visualize the model graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose how to build your model below. Just uncomment which function you'd like to use. You'll notice that the plot will look the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'wrappers' from 'tensorflow.python.keras.layers' (/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/layers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/TensorFlow-Advanced-Techniques-Specialization/C1_W1_Lab_1_functional-practice.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f75736d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/TensorFlow-Advanced-Techniques-Specialization/C1_W1_Lab_1_functional-practice.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m modelF \u001b[39m=\u001b[39m build_model_with_functional()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f75736d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/TensorFlow-Advanced-Techniques-Specialization/C1_W1_Lab_1_functional-practice.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m#model = build_model_with_sequential()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f75736d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/TensorFlow-Advanced-Techniques-Specialization/C1_W1_Lab_1_functional-practice.ipynb#ch0000009vscode-remote?line=2'>3</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f75736d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/TensorFlow-Advanced-Techniques-Specialization/C1_W1_Lab_1_functional-practice.ipynb#ch0000009vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m# Plot model graph\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f75736d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/TensorFlow-Advanced-Techniques-Specialization/C1_W1_Lab_1_functional-practice.ipynb#ch0000009vscode-remote?line=4'>5</a>\u001b[0m plot_model(modelF, show_shapes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, show_layer_names\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, to_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmodel.png\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/vis_utils.py:322\u001b[0m, in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkeras.utils.plot_model\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    279\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_model\u001b[39m(model,\n\u001b[1;32m    280\u001b[0m                to_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel.png\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m                expand_nested\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    286\u001b[0m                dpi\u001b[39m=\u001b[39m\u001b[39m96\u001b[39m):\n\u001b[1;32m    287\u001b[0m   \u001b[39m\"\"\"Converts a Keras model to dot format and save to a file.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \n\u001b[1;32m    289\u001b[0m \u001b[39m  Example:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39m    This enables in-line display of the model plots in notebooks.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m   dot \u001b[39m=\u001b[39m model_to_dot(\n\u001b[1;32m    323\u001b[0m       model,\n\u001b[1;32m    324\u001b[0m       show_shapes\u001b[39m=\u001b[39;49mshow_shapes,\n\u001b[1;32m    325\u001b[0m       show_dtype\u001b[39m=\u001b[39;49mshow_dtype,\n\u001b[1;32m    326\u001b[0m       show_layer_names\u001b[39m=\u001b[39;49mshow_layer_names,\n\u001b[1;32m    327\u001b[0m       rankdir\u001b[39m=\u001b[39;49mrankdir,\n\u001b[1;32m    328\u001b[0m       expand_nested\u001b[39m=\u001b[39;49mexpand_nested,\n\u001b[1;32m    329\u001b[0m       dpi\u001b[39m=\u001b[39;49mdpi)\n\u001b[1;32m    330\u001b[0m   to_file \u001b[39m=\u001b[39m path_to_string(to_file)\n\u001b[1;32m    331\u001b[0m   \u001b[39mif\u001b[39;00m dot \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/vis_utils.py:98\u001b[0m, in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkeras.utils.model_to_dot\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_to_dot\u001b[39m(model,\n\u001b[1;32m     68\u001b[0m                  show_shapes\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m                  dpi\u001b[39m=\u001b[39m\u001b[39m96\u001b[39m,\n\u001b[1;32m     74\u001b[0m                  subgraph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     75\u001b[0m   \u001b[39m\"\"\"Convert a Keras model to dot format.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[1;32m     77\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m    ImportError: if graphviz or pydot are not available.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m wrappers\n\u001b[1;32m     99\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m sequential\n\u001b[1;32m    100\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m functional\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'wrappers' from 'tensorflow.python.keras.layers' (/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "modelF = build_model_with_functional()\n",
    "#model = build_model_with_sequential()\n",
    "\n",
    "# Plot model graph\n",
    "plot_model(modelF, show_shapes=True, show_layer_names=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'wrappers' from 'tensorflow.python.keras.layers' (/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/layers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/TensorFlow-Advanced-Techniques-Specialization/C1_W1_Lab_1_functional-practice.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f75736d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/TensorFlow-Advanced-Techniques-Specialization/C1_W1_Lab_1_functional-practice.ipynb#ch0000010vscode-remote?line=1'>2</a>\u001b[0m modelS \u001b[39m=\u001b[39m build_model_with_sequential()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f75736d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/TensorFlow-Advanced-Techniques-Specialization/C1_W1_Lab_1_functional-practice.ipynb#ch0000010vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m# Plot model graph\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f75736d616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3130362e3234302e3233342e313135227d7d/TensorFlow-Advanced-Techniques-Specialization/C1_W1_Lab_1_functional-practice.ipynb#ch0000010vscode-remote?line=4'>5</a>\u001b[0m plot_model(modelS, show_shapes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, show_layer_names\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, to_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmodel.png\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/vis_utils.py:322\u001b[0m, in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkeras.utils.plot_model\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    279\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_model\u001b[39m(model,\n\u001b[1;32m    280\u001b[0m                to_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel.png\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m                expand_nested\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    286\u001b[0m                dpi\u001b[39m=\u001b[39m\u001b[39m96\u001b[39m):\n\u001b[1;32m    287\u001b[0m   \u001b[39m\"\"\"Converts a Keras model to dot format and save to a file.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \n\u001b[1;32m    289\u001b[0m \u001b[39m  Example:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39m    This enables in-line display of the model plots in notebooks.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m   dot \u001b[39m=\u001b[39m model_to_dot(\n\u001b[1;32m    323\u001b[0m       model,\n\u001b[1;32m    324\u001b[0m       show_shapes\u001b[39m=\u001b[39;49mshow_shapes,\n\u001b[1;32m    325\u001b[0m       show_dtype\u001b[39m=\u001b[39;49mshow_dtype,\n\u001b[1;32m    326\u001b[0m       show_layer_names\u001b[39m=\u001b[39;49mshow_layer_names,\n\u001b[1;32m    327\u001b[0m       rankdir\u001b[39m=\u001b[39;49mrankdir,\n\u001b[1;32m    328\u001b[0m       expand_nested\u001b[39m=\u001b[39;49mexpand_nested,\n\u001b[1;32m    329\u001b[0m       dpi\u001b[39m=\u001b[39;49mdpi)\n\u001b[1;32m    330\u001b[0m   to_file \u001b[39m=\u001b[39m path_to_string(to_file)\n\u001b[1;32m    331\u001b[0m   \u001b[39mif\u001b[39;00m dot \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/vis_utils.py:98\u001b[0m, in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkeras.utils.model_to_dot\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_to_dot\u001b[39m(model,\n\u001b[1;32m     68\u001b[0m                  show_shapes\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m                  dpi\u001b[39m=\u001b[39m\u001b[39m96\u001b[39m,\n\u001b[1;32m     74\u001b[0m                  subgraph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     75\u001b[0m   \u001b[39m\"\"\"Convert a Keras model to dot format.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[1;32m     77\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m    ImportError: if graphviz or pydot are not available.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m wrappers\n\u001b[1;32m     99\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m sequential\n\u001b[1;32m    100\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m functional\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'wrappers' from 'tensorflow.python.keras.layers' (/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "#model = build_model_with_functional()\n",
    "modelS = build_model_with_sequential()\n",
    "\n",
    "# Plot model graph\n",
    "plot_model(modelS, show_shapes=True, show_layer_names=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Regardless if you built it with the Sequential or Functional API, you'll follow the same steps when training and evaluating your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4990 - accuracy: 0.8249\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3755 - accuracy: 0.8643\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.3353 - accuracy: 0.8779\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.3119 - accuracy: 0.8856\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2951 - accuracy: 0.8915\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.3410 - accuracy: 0.8772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34098407319784163, 0.8772]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare fashion mnist dataset\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# configure, train, and evaluate the model\n",
    "modelS.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "modelS.fit(training_images, training_labels, epochs=5)\n",
    "modelS.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4963 - accuracy: 0.8253\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.3780 - accuracy: 0.8638\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.3375 - accuracy: 0.8766\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.3134 - accuracy: 0.8840\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2948 - accuracy: 0.8909\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.3833 - accuracy: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3833023797035217, 0.8624]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare fashion mnist dataset\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# configure, train, and evaluate the model\n",
    "modelF.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "modelF.fit(training_images, training_labels, epochs=5)\n",
    "modelF.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "FunctionalCoLab1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
